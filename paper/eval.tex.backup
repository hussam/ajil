In this section, we evaluate the \sysname{} protocol by simulation. The simulator uses the previously described algorithm and some simple acceptable use policies.

Our evaluation has multiple goals. We first test our protocol's rate-limiting capabilities with a couple of multicast traffic patterns. We then evaluate the effects of manipulating the protocol's parameters as part of the AUP. Additionally we test how the slowdown policy is being applied across groups and individual communication channels. Finally we test two simple administrator-defined slowdown mechanisms and highlight their differing effects.

\subsection{Setup}
We based the setup of our nodes and multicast groups on a previously-acquired multicast trace of an IBM Websphere depolyment[XX]. That trace showed an interenal publish-subscribe component of Websphere using over 6,600 multicast groups averaging 10 members per group.

Our simulater generates multiple communication patterns to reflect different data center deployments. During initialization, nodes subscribe to the various multicast groups and read-in a communication file dictating the number and sizes of messages to be sent during each epoch. This communication file simulates the application load; from the perspective of our protocol, during each epoch the application sends-in multicast requests down to the protocol which puts them down on the network as long as its current quota has not been exceeded. At the end of each epoch, each node revalutes its sending quota for each multicast channel on each group. We have assumed a model in which sending packets up to the current quota and then dropping the rest is acceptable. As mentioned before, this is model mimics many real-life scenarios.

\subsection{Rate-Limiting}
\begin{figure*}[ht]
 \centering
 \includegraphics[scale=1]{figures/evaluation/rate-limiting/ajil-peek.eps}
 \includegraphics[scale=1]{figures/evaluation/rate-limiting/ajil-square.eps}
 \caption{IPMC traffic rate-limited by \sysname{} under different communication patterns.}
 \label{fig:rate-limiting}
\end{figure*}

Figure ~\ref{fig:rate-limiting} shows the aggergate multicast traffic of a network that has been limited to 600 KBps. The figure depicts two communication patterns. Both networks start with traffic rates of about 400KBps. The first graph on the left shows a gradual increase of the communication rate to over 800KBps and then a graduate decline. This pattern could rise in situations where multicast groups are setup dynamically to execute certain tasks and are then deleted. A gradual incline/decline rises in situations with inter-dependencies between the tasks being executed. So an increasing number of ``flash groups'' could be set up to process a set of tasks, and as soon as the root job has been executed all the dependencies start to finalize and terminate. We know of at least one widely deployed commericial application in which this is the case (\textit{[NOTE: should i say it is websphere??]}).

The second graph on the right represents a more common case. The aggregate traffic in the network is steady at around 400KBps when suddenly an event, or a faulty process, triggers high multicast rates which push the aggregate traffic over the set limit. As soon as that event terminates the traffic rates go back to the normal rates.

Both graphs in figure ~\ref{fig:rate-limiting} show that \sysname{} does not affect the multicast rates as long as they do not exceed the limit. Once the limit is exceeded, \sysname{} minimizes the excess. Notice that the lower peeks above the limit line in both graphs are those of rate-limited IPMC. Eventhough the raw traffic rates exceed the limit by over 20\%, \sysname{} severly minimizes that excess.

In this experiment we set the protocol parameters to: $\alpha=0.5, \beta=0.25$, and a monitor broadcast factor $c=0.01$. Notice that in both graphs the aggregate broadcast traffic used by all the monitors is reported at the bottom and is minimal to the aggregate multicast traffic in use.

\subsection{Reaction Domain Size}
We tested various sizes for the reaction domain trying to determine an optimal selection. We note that the effects of the size of the reaction domain are largely dependent on the slowdown mechanism specified by the administrator. For example, using a slowdown mechanism that scales back the quotas for all the senders by a fixed percentage and setting the reaction domain such that it encompasses all the nodes in all the groups has the effect of scaling down the entire network when the global limit is violated. On the other hand, if the administrator wishes to balance the multicast bandwidth consumption by all the nodes, she might opt for choosing smaller reaction domains and implementing a slowdown mechanism that scales back the top senders to either a fixed upper-limit or by a fraction of their previous sending quota.

\begin{figure}[t]
 \centering
 \includegraphics[scale=1]{figures/evaluation/rd/reaction-waves.eps}
 \caption{The oscillation effect in different reaction domain sizes.}
 \label{fig:varied-rd}
\end{figure}

However we observe that regardless of the slowdown mechasim that is used, a certain pattern emerges. Since nodes use the data of the previous epoch to estimate the global traffic for the next epoch, it is often the case that when a group of nodes slowdown in an epoch, the aggregate traffic in the subsequent epoch falls below the global limit. This can be either because of the slowdown mechanism being applied, or because other senders that were not part of the reaction domain have reduced their rates as well because of a reduced demand by the application. In that case, all the nodes that slowed down in the previous epoch will decide to increase their quota in the next epoch. This will result in exceeding the limit in the next epoch. This pattern of overshooting and undershooting can continue for multiple epochs. The end result is for a traffic rate that is oscillating around the traffic rate.

\begin{figure*}[t]
 \centering
 \includegraphics[scale=1]{figures/evaluation/staleness/excess-during.eps}
 \includegraphics[scale=1]{figures/evaluation/staleness/utility-after.eps}
 \caption{The effects of monitor staleness.}
 \label{fig:monitor-staleness}
\end{figure*}

This oscillation, however, dampens with time. This is caused by several factors: first, when nodes increase their quota after being slowed down, they do that in a multiplicative way, and the quota increase amounts to 50\% of the quota reduction implemented in the previous epoch. In addition to that, nodes that are currently applying a slowdown policy do not decrease their quota after they have increased it. This means that the multiplicative increases can not be rolled back after they have been used. So in each epoch, the percentage by which a node in the reaction domain can speed up and slow down is monotonically decreasing. Thus this oscillatory behavior dampens with time.

However, the speed of this dampening depends on the size of the reaction domain. In large reaction domains, the oscillation is bigger in magnititude because there are more nodes that can potentially slowdown or speed up after each epoch. Figure ~\ref{fig:varied-rd} shows the oscillatory behavior of different reaction domains. In this experiment we fixed the communication pattern, and the network setup while varying the size of the reaction domain. We set the $(\alpha, \beta)$ parameters to: (1,1) which is 100\% of the nodes, and (1, 0.5), (0.5, 0.5), (0.5, 0.25) which roughly correspond to 50\%, 25\% and 12.5\% of all the nodes in a setting were the nodes are equally distributed among all the groups. Figure ~\ref{fig:varied-rd} plots the percentage of the execess traffic being sent compared to the set limit. So a value of +5\% denotes exceeding the limit by 5\%, and -5\% denotes sending 5\% below the limit. Figure ~\ref{fig:varied-rd} shows that smaller reaction domains experience smaller oscillation as expected.

\subsection{Monitor Staleness}

As explained previously, nodes rely on the monitor component of the protocol to gather data about the sending patterns of other nodes and other groups in the system. Nodes then use that collected information to make local decisions on whether to invoke the reactor and apply the slowdown policy. Monitors use a broadcast channel and probabilistically publish the traffic rates of their nodes. In this experiment we manipulated the monitor broadcast frequency ($c$) to measure its effect on the responsiveness of the protocol. A low broadcast frequency implies a lower probability for a particular monitor to publish its most recent information, which also implies that nodes often have to rely on old stale data when revaluating the sending quota between epochs. This staleness implies a slower reaction to a limit violation, and a slower speedup after the violation has been removed.

Figure ~\ref{fig:monitor-staleness} shows the affect of the broadcast frequency $c$ on the responsiveness of the protocol. We used the square wave traffic pattern as shown in the right graph of figure ~\ref{fig:rate-limiting} where the limit is being exceeded between time 350 and 700. We measured the responsiveness of the system under two broadcast frequencies: $c=0.1$ which has been used for the rest of the experiments, and a smaller $c=0.001$. The first graph on the left in figure ~\ref{fig:monitor-staleness} shows the percentage by which \sysname{} overshoots the limit during the time the limit is being exceeded. As expected, with a smaller broadcast frequency, nodes are less aware of the changes in the sending patterns of other nodes, and thus protocol overshoots the beyond the limit by a larger fraction than that experienced by the larger $c$ value.

The broadcast frequency also affects the responsiveness of the protocol in recovering from a limit violation. The second part on the right of figure ~\ref{fig:monitor-staleness} shows how quickly the protocol recovering from the limit violation. The graph shows the alloted quota as a percentage of the requested quota after the limit violation has ended. In an optimal case, the utility should be 100\% immediately after time $t=700$, since that is when the spike ends as shown in figure ~\ref{fig:rate-limiting}. As expected, we see that a higher broadcast fraction results in a faster recovery from a limit violation.


\subsection{Fairness of Utility}

\begin{figure*}[t]
 \centering
 \includegraphics[scale=1]{figures/evaluation/fairness/utility-rd1.eps}
 \includegraphics[scale=1]{figures/evaluation/fairness/utility-rd.125.eps}
 \caption{The average ratio of the allotted quota to the requested quota of each group and channel}
 \label{fig:utility}
\end{figure*}

We acheived rate-limiting by slowing down a subset of the senders in the system. However, in the worst case scenario this could result in a subset of the senders being completely denied multicast access while other nodes receive the full bandwidth quota that they ask for. We define \textit{utility} as the fraction of the requested bandwidth quota that has been alloted to the node. We get a sense of the \textit{fairness} of the protocol by analyzing the variance of the utilities on each multicast group. We can also measure the utility of each sender on each multicast group (a per channel utility). Intuitively, the fairness of the protocol depends on the administrator's policy and the protocol parameters.

Figure ~\ref{fig:utility} shows the utility per channel and per group for the same network under two different policies. In both cases the slowdown policy has been set to slowdown the nodes in the reaction domain by a percentage that is proportional to the fraction of traffic being sent in excess above the global rate limit. However, in the first graph on the left the reaction domain has been set to include all the nodes and all the senders (i.e. the entire network scales back when the limit is violated). Meanwhile, the second graph on the left uses the 12.5\% reaction domain ($\alpha=0.5, \beta=0.25$) that we have seen before.

As expected, the variance of the group utility is much lower with the reaction domain is larger because more groups are being scaled back. In both cases the variance of the channels utility is larger than the variance of the groups utility. This is because the uniform distribution of nodes to groups results in having the bandwidth demands for groups be very comprable (remember, there are far less groups in the system than ``per-node channels''). However, each channel represents the multicast demands of a single node on a single group. So channels are much more varied by definition. This means that when channels with low demands are slowed down their nodes will increase and regain their quotas quickly because they do not contribute much to the overall aggregate traffic and will thus find the capacity to increase their quotas. This means that low demand channels can acheive 100\% utility much easier than large demand channels. This hetrogenity in channels demands results in a more varied utility for them, which explains the higher variance we see in figure ~\ref{fig:utility} for channels when compared to groups.


\subsection{Policy}
In the experiments we ran so far, we have used a single slowdown policy. The slowdown mechanism involved reducing the quota of all the nodes in the reaction domain by the same fraction as the excess in multicast traffic above the aggregate limit. However, as elluded to before, the choice of policy has direct impact on the performance of the protocol.

\begin{figure*}[t]
 \centering
 \includegraphics{figures/evaluation/policy/ajil-policy1.eps}
 \includegraphics{figures/evaluation/policy/channels-utility.eps}
 \includegraphics{figures/evaluation/policy/ajil-policy2.eps}
 \includegraphics{figures/evaluation/policy/groups-utility.eps}
 \caption{The top row implements a slowdown policy reducing the sending quota by the fraction of traffic excess. The bottom row implements a slowdown policy reducing the sending quota by a fixed rate.}
 \label{fig:policy}
\end{figure*}

In this experiment we implemented another slowdown policy with a strict and naive slowdown mechanism dictating that nodes in the reaction domain set their quotas to 0 in the first epoch in which they are in the reaction domain, and the multiplicatively increase their quota (by multiplicitively decreasing the slowdown amount by 50\% if possible). As figure ~\ref{fig:policy} shows, although this policy quickly reduces the violating traffic, it does not result in fairly distributed group and channel utilities.